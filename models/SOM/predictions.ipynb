{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SOM import SOM\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "from utils import load_csv, dataloader, load_save_models\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "import preprocessing.tiff_handling as tiff_handling\n",
    "import plotly.express as px\n",
    "from stats import evaluate_perf_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 100\n",
    "map_dim = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./hpc_SOM_model.pkl.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<minisom.MiniSom at 0x783548016990>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SOM.load_model(SOM(input_dim=input_dim,map_dim=map_dim),'./hpc_SOM_model.pkl')\n",
    "model.som"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bendm/machine_learning/project/majority-vote-outlier-detection/models/SOM/../../utils/load_csv.py:20: DtypeWarning: Columns (91,94,209,213) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  frame = pd.read_csv(data_path, delimiter=\";\").iloc[:, -3:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outlier test validation: False\n"
     ]
    }
   ],
   "source": [
    "set = load_csv.load_pandas()\n",
    "train, val,test = load_csv.split_data(set)\n",
    "\n",
    "print(f'outlier test validation: {any(val[\"classification\"]!=1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = v2.Compose(\n",
    "    [\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((60, 80)),\n",
    "        # v2.Lambda(\n",
    "        #     lambda x: (x.view(-1) - torch.min(x)) / (torch.max(x) - torch.min(x))\n",
    "        # ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_data = np.array(\n",
    "    [\n",
    "        tiff_handling.flatten_image(transform(tiff_handling.handle_tiff(el)))\n",
    "        for el in val[\"file_names\"].tolist()\n",
    "    ]\n",
    ")\n",
    "\n",
    "test[\"image\"] = test[\"file_names\"].apply(lambda x: tiff_handling.flatten_image(transform(tiff_handling.handle_tiff(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 22:05:48,172] A new study created in memory with name: no-name-d5b68005-1f29-4b4c-bde8-25698b6ad886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 2.8702 (Percentile: 95)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 22:17:54,493] Trial 0 finished with value: 0.7945439045183291 and parameters: {'percentile': 95}. Best is trial 0 with value: 0.7945439045183291.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 2.3000 (Percentile: 80)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 22:30:14,541] Trial 1 finished with value: 0.8269364968597348 and parameters: {'percentile': 80}. Best is trial 1 with value: 0.8269364968597348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 5.7133 (Percentile: 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 22:42:11,089] Trial 2 finished with value: 0.6695772058823529 and parameters: {'percentile': 100}. Best is trial 1 with value: 0.8269364968597348.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 2.4062 (Percentile: 85)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 22:54:36,556] Trial 3 finished with value: 0.832 and parameters: {'percentile': 85}. Best is trial 3 with value: 0.832.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 2.5560 (Percentile: 90)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-03 23:07:05,579] Trial 4 finished with value: 0.8363522798251093 and parameters: {'percentile': 90}. Best is trial 4 with value: 0.8363522798251093.\n"
     ]
    }
   ],
   "source": [
    "# optimize percentile of error threshold\n",
    "import optuna\n",
    "\n",
    "truth = [1 if value == 1 else 0 for value in test[\"classification\"]]\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    perc = trial.suggest_int(\"percentile\", 80,100,step=5)\n",
    "    model.set_threshold(val_data,perc)\n",
    "    output = model.predict(test)\n",
    "\n",
    "    perf_metrics = evaluate_perf_utils.evaluate_performance(truth, output[\"prediction\"])\n",
    "    return perf_metrics[\"f1\"]\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best percentile: 90\n",
      "best f1: 0.8363522798251093\n"
     ]
    }
   ],
   "source": [
    "print(f\"best percentile: {study.best_params['percentile']}\")\n",
    "print(f\"best f1: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold set at 2.5560 (Percentile: 90)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(2.5559949231468084)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_threshold(val_data,percentile=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tn': np.int64(1051),\n",
       " 'fp': np.int64(406),\n",
       " 'fn': np.int64(118),\n",
       " 'tp': np.int64(1339),\n",
       " 'precision': np.float64(0.7673352435530086),\n",
       " 'recall': np.float64(0.9190116678105696),\n",
       " 'f1': np.float64(0.8363522798251093)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth = [1 if value == 1 else 0 for value in output['classification']]\n",
    "\n",
    "perf_metrics = evaluate_perf_utils.evaluate_performance(truth, output['prediction'])\n",
    "tn = perf_metrics['tn']\n",
    "tp = perf_metrics['tp']\n",
    "fn = perf_metrics['fn']\n",
    "fp = perf_metrics['fp']\n",
    "precision = perf_metrics['precision']\n",
    "recall = perf_metrics['recall']\n",
    "f1 = perf_metrics['f1']\n",
    "\n",
    "perf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.820178448867536\n"
     ]
    }
   ],
   "source": [
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(f'accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
